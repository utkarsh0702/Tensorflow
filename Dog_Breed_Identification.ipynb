{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dog Breed Identification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO911VIXT6BuRDug1u0dOcQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/utkarsh0702/Tensorflow/blob/master/Dog_Breed_Identification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhB1lvCRmywn"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import os\r\n",
        "from tensorflow import keras\r\n",
        "import zipfile\r\n",
        "from google.colab import files\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from google.colab import files\r\n",
        "from tensorflow.keras.preprocessing import image\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import matplotlib as mpl"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxW1qKR7TlPt"
      },
      "source": [
        "mpl.rcParams['figure.figsize'] = (10,8)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6-U-nnlm-jU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2de9a893-ef85-41f7-89be-6af15d7f495b"
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\r\n",
        "if device_name != '/device:GPU:0':\r\n",
        "  raise SystemError('GPU device not found')\r\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hgpfs28YnH8P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3a14da4-81aa-42b8-b9b0-c4fcbdf3c73b"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvWwQeFbnH3V"
      },
      "source": [
        "local_zip= '/content/drive/My Drive/datasets/dog-breed-identification.zip'\r\n",
        "zip_ref= zipfile.ZipFile(local_zip, 'r')\r\n",
        "zip_ref.extractall('/content')\r\n",
        "zip_ref.close()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbbjgclGnHzJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "075b6580-b8ef-4d12-f184-7509ed4923ac"
      },
      "source": [
        "df= pd.read_csv('labels.csv')\r\n",
        "df"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>breed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
              "      <td>boston_bull</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
              "      <td>dingo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>001cdf01b096e06d78e9e5112d419397</td>\n",
              "      <td>pekinese</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n",
              "      <td>bluetick</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
              "      <td>golden_retriever</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10217</th>\n",
              "      <td>ffd25009d635cfd16e793503ac5edef0</td>\n",
              "      <td>borzoi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10218</th>\n",
              "      <td>ffd3f636f7f379c51ba3648a9ff8254f</td>\n",
              "      <td>dandie_dinmont</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10219</th>\n",
              "      <td>ffe2ca6c940cddfee68fa3cc6c63213f</td>\n",
              "      <td>airedale</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10220</th>\n",
              "      <td>ffe5f6d8e2bff356e9482a80a6e29aac</td>\n",
              "      <td>miniature_pinscher</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10221</th>\n",
              "      <td>fff43b07992508bc822f33d8ffd902ae</td>\n",
              "      <td>chesapeake_bay_retriever</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10222 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     id                     breed\n",
              "0      000bec180eb18c7604dcecc8fe0dba07               boston_bull\n",
              "1      001513dfcb2ffafc82cccf4d8bbaba97                     dingo\n",
              "2      001cdf01b096e06d78e9e5112d419397                  pekinese\n",
              "3      00214f311d5d2247d5dfe4fe24b2303d                  bluetick\n",
              "4      0021f9ceb3235effd7fcde7f7538ed62          golden_retriever\n",
              "...                                 ...                       ...\n",
              "10217  ffd25009d635cfd16e793503ac5edef0                    borzoi\n",
              "10218  ffd3f636f7f379c51ba3648a9ff8254f            dandie_dinmont\n",
              "10219  ffe2ca6c940cddfee68fa3cc6c63213f                  airedale\n",
              "10220  ffe5f6d8e2bff356e9482a80a6e29aac        miniature_pinscher\n",
              "10221  fff43b07992508bc822f33d8ffd902ae  chesapeake_bay_retriever\n",
              "\n",
              "[10222 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFSj6Xz3T6lz"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUkho0L_E6eU"
      },
      "source": [
        "**Choosing specific Dog Breeds**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "2QggSmxHE3mC",
        "outputId": "309047ae-fbbc-4d3d-910b-82726dc5995e"
      },
      "source": [
        "breeds=['beagle', 'chihuahua', 'doberman','french_bulldog', 'golden_retriever', 'malamute', 'pug', 'saint_bernard', 'scottish_deerhound','tibetan_mastiff']\r\n",
        "df1 = df.loc[df['breed'].apply(lambda x: any([k in x for k in breeds]))]\r\n",
        "df1.head(10)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>breed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
              "      <td>golden_retriever</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0042188c895a2f14ef64a918ed9c7b64</td>\n",
              "      <td>scottish_deerhound</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>008b1271ed1addaccf93783b39deab45</td>\n",
              "      <td>doberman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>00a366d4b4a9bbb6c8a63126697b7656</td>\n",
              "      <td>golden_retriever</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0100f55e4f0fe28f2c0465d3fc4b9897</td>\n",
              "      <td>golden_retriever</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>01e787576c003930f96c966f9c3e1d44</td>\n",
              "      <td>scottish_deerhound</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>01f429667104c0c5a5f321700f15435c</td>\n",
              "      <td>malamute</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>0206c12e8984e3c8a166cc272de25d6f</td>\n",
              "      <td>chihuahua</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>023e4e28415506e0deddcbd8f8bdab29</td>\n",
              "      <td>pug</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>02508e76981e1ba059d785704b4c480c</td>\n",
              "      <td>pug</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  id               breed\n",
              "4   0021f9ceb3235effd7fcde7f7538ed62    golden_retriever\n",
              "9   0042188c895a2f14ef64a918ed9c7b64  scottish_deerhound\n",
              "20  008b1271ed1addaccf93783b39deab45            doberman\n",
              "25  00a366d4b4a9bbb6c8a63126697b7656    golden_retriever\n",
              "37  0100f55e4f0fe28f2c0465d3fc4b9897    golden_retriever\n",
              "79  01e787576c003930f96c966f9c3e1d44  scottish_deerhound\n",
              "82  01f429667104c0c5a5f321700f15435c            malamute\n",
              "84  0206c12e8984e3c8a166cc272de25d6f           chihuahua\n",
              "92  023e4e28415506e0deddcbd8f8bdab29                 pug\n",
              "97  02508e76981e1ba059d785704b4c480c                 pug"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gGP17P7RlNq",
        "outputId": "8d8622f3-521b-47f7-9a38-12b715fd4daf"
      },
      "source": [
        "# added .jpg at the end of each object in id column\r\n",
        "df1.id = df1.id + '.jpg'"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py:5170: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[name] = value\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onXXpJFlIWkj",
        "outputId": "3bb87abe-d36c-41cc-eaeb-52991ba4e6ab"
      },
      "source": [
        "df1['breed'].value_counts()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "scottish_deerhound    126\n",
              "beagle                105\n",
              "pug                    94\n",
              "saint_bernard          84\n",
              "malamute               81\n",
              "doberman               74\n",
              "chihuahua              71\n",
              "french_bulldog         70\n",
              "tibetan_mastiff        69\n",
              "golden_retriever       67\n",
              "Name: breed, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjA9agXJbIXi"
      },
      "source": [
        "# breed_number = {'beagle':0, 'chihuahua':1, 'doberman':2,'french_bulldog':3, 'golden_retriever':4,\r\n",
        "#                    'malamute':5, 'pug':6, 'saint_bernard':7, 'scottish_deerhound':8,'tibetan_mastiff':9}\r\n",
        "# for i in breed_number:\r\n",
        "#   df1['breed'].replace(i, breed_number[i], inplace = True)\r\n",
        "# df1"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQ-4k1bPEy8w",
        "outputId": "ca3df9e2-8b84-4235-8e6f-b0a4ab9cd354"
      },
      "source": [
        "datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255, validation_split=0.1)\r\n",
        "\r\n",
        "train_generator = datagen.flow_from_dataframe(\r\n",
        "    df1,\r\n",
        "    directory=\"train/\",\r\n",
        "    x_col=\"id\",\r\n",
        "    y_col=\"breed\",\r\n",
        "    target_size=(224, 224),\r\n",
        "    batch_size=32, \r\n",
        "    subset=\"training\")\r\n",
        "\r\n",
        "validation_generator = datagen.flow_from_dataframe(\r\n",
        "    df1,\r\n",
        "    directory=\"train/\",\r\n",
        "    x_col=\"id\",\r\n",
        "    y_col=\"breed\",\r\n",
        "    target_size=(224, 224),\r\n",
        "    batch_size=32,\r\n",
        "    subset=\"validation\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 757 validated image filenames belonging to 10 classes.\n",
            "Found 84 validated image filenames belonging to 10 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMrpVphBTwMv"
      },
      "source": [
        "# Transfer Learning with ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDUnPJTMUDbm",
        "outputId": "41bdae0f-32d6-4625-e5ae-20296d76ac03"
      },
      "source": [
        "feature_extractor = keras.applications.ResNet50(input_shape=(224,224,3), include_top=False, weights='imagenet')\r\n",
        "feature_extractor.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n",
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 23,534,592\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOkwCXEES-52"
      },
      "source": [
        "# Finding a suitable learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lT-dOLuGS9cQ",
        "outputId": "a0fc596a-6d28-410d-e366-dc9c522be6d9"
      },
      "source": [
        "keras.backend.clear_session()\r\n",
        "\r\n",
        "model= keras.Sequential([\r\n",
        "                         feature_extractor,\r\n",
        "                         keras.layers.GlobalAveragePooling2D(),\r\n",
        "                         keras.layers.Flatten(),\r\n",
        "                         keras.layers.Dense(128, activation=\"relu\"),\r\n",
        "                         keras.layers.Dropout(0.4),\r\n",
        "                         keras.layers.Dense(64, activation=\"relu\"),\r\n",
        "                         keras.layers.Dropout(0.4),\r\n",
        "                         keras.layers.Dense(10, activation= \"sigmoid\")\r\n",
        "])\r\n",
        "model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50 (Functional)        (None, 7, 7, 2048)        23587712  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 23,858,890\n",
            "Trainable params: 23,805,770\n",
            "Non-trainable params: 53,120\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzqoTGVBS9cr"
      },
      "source": [
        "num_layers= 6\r\n",
        "feature_extractor.trainable= True;\r\n",
        "for Layers in model.layers[-num_layers:]:\r\n",
        "  Layers.trainable= True"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SecvwvwvS9cr"
      },
      "source": [
        "# STEP_SIZE_TRAIN = int(np.ceil(train_generator.n / train_generator.batch_size))\r\n",
        "# STEP_SIZE_VAL = int(np.ceil(validation_generator.n / validation_generator.batch_size))\r\n",
        "\r\n",
        "# print(\"Train step size:\", STEP_SIZE_TRAIN)\r\n",
        "# print(\"Validation step size:\", STEP_SIZE_VAL)\r\n",
        "\r\n",
        "# train_generator.reset()\r\n",
        "# validation_generator.reset()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJpgrtIUS9cs"
      },
      "source": [
        "lr_schedular= tf.keras.callbacks.LearningRateScheduler(lambda x: 1e-5*10**(x/20))\r\n",
        "checkpoint = keras.callbacks.ModelCheckpoint('dog_breed_classifier_model.h5', \r\n",
        "                                             monitor='val_accuracy', \r\n",
        "                                             verbose=1, save_best_only=True, \r\n",
        "                                             mode='max', save_weights_only=True)\r\n",
        "\r\n",
        "model.compile(\r\n",
        "    optimizer= keras.optimizers.Adam(learning_rate=1e-5),\r\n",
        "    loss= keras.losses.CategoricalCrossentropy(),\r\n",
        "    metrics=['accuracy']\r\n",
        ")"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5-VCLcNS9ct",
        "outputId": "806a3a9e-7bbd-4b6a-88f1-5e214a96e730"
      },
      "source": [
        "history = model.fit(train_generator,\r\n",
        "                    validation_data=validation_generator, verbose=1,\r\n",
        "                    epochs=50, callbacks=[lr_schedular, checkpoint])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "24/24 [==============================] - 15s 418ms/step - loss: 2.4289 - accuracy: 0.1124 - val_loss: 2.3831 - val_accuracy: 0.0476\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.04762, saving model to dog_breed_classifier_model.h5\n",
            "Epoch 2/150\n",
            "24/24 [==============================] - 9s 384ms/step - loss: 2.2816 - accuracy: 0.1552 - val_loss: 2.2765 - val_accuracy: 0.1310\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.04762 to 0.13095, saving model to dog_breed_classifier_model.h5\n",
            "Epoch 3/150\n",
            "24/24 [==============================] - 9s 378ms/step - loss: 2.1943 - accuracy: 0.1919 - val_loss: 2.1994 - val_accuracy: 0.1905\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.13095 to 0.19048, saving model to dog_breed_classifier_model.h5\n",
            "Epoch 4/150\n",
            "24/24 [==============================] - 9s 370ms/step - loss: 2.1119 - accuracy: 0.2223 - val_loss: 2.1100 - val_accuracy: 0.2738\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.19048 to 0.27381, saving model to dog_breed_classifier_model.h5\n",
            "Epoch 5/150\n",
            "24/24 [==============================] - 9s 365ms/step - loss: 1.9685 - accuracy: 0.2958 - val_loss: 2.0066 - val_accuracy: 0.3810\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.27381 to 0.38095, saving model to dog_breed_classifier_model.h5\n",
            "Epoch 6/150\n",
            "24/24 [==============================] - 9s 362ms/step - loss: 1.8223 - accuracy: 0.3699 - val_loss: 1.9181 - val_accuracy: 0.3929\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.38095 to 0.39286, saving model to dog_breed_classifier_model.h5\n",
            "Epoch 7/150\n",
            "24/24 [==============================] - 9s 362ms/step - loss: 1.7128 - accuracy: 0.4560 - val_loss: 1.8321 - val_accuracy: 0.4048\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.39286 to 0.40476, saving model to dog_breed_classifier_model.h5\n",
            "Epoch 8/150\n",
            "24/24 [==============================] - 9s 365ms/step - loss: 1.5782 - accuracy: 0.5148 - val_loss: 1.7528 - val_accuracy: 0.4643\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.40476 to 0.46429, saving model to dog_breed_classifier_model.h5\n",
            "Epoch 9/150\n",
            "24/24 [==============================] - 9s 368ms/step - loss: 1.4462 - accuracy: 0.5899 - val_loss: 1.6883 - val_accuracy: 0.4762\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.46429 to 0.47619, saving model to dog_breed_classifier_model.h5\n",
            "Epoch 10/150\n",
            "24/24 [==============================] - 9s 371ms/step - loss: 1.2933 - accuracy: 0.6075 - val_loss: 1.6645 - val_accuracy: 0.4524\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.47619\n",
            "Epoch 11/150\n",
            "24/24 [==============================] - 9s 375ms/step - loss: 1.1413 - accuracy: 0.6799 - val_loss: 1.6015 - val_accuracy: 0.4881\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.47619 to 0.48810, saving model to dog_breed_classifier_model.h5\n",
            "Epoch 12/150\n",
            "24/24 [==============================] - 9s 375ms/step - loss: 0.9533 - accuracy: 0.7765 - val_loss: 1.5662 - val_accuracy: 0.5357\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.48810 to 0.53571, saving model to dog_breed_classifier_model.h5\n",
            "Epoch 13/150\n",
            "24/24 [==============================] - 9s 380ms/step - loss: 0.7211 - accuracy: 0.8437 - val_loss: 1.5509 - val_accuracy: 0.5238\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.53571\n",
            "Epoch 14/150\n",
            "24/24 [==============================] - 9s 369ms/step - loss: 0.5848 - accuracy: 0.8335 - val_loss: 1.6078 - val_accuracy: 0.5238\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.53571\n",
            "Epoch 15/150\n",
            "24/24 [==============================] - 9s 367ms/step - loss: 0.4898 - accuracy: 0.8951 - val_loss: 1.5810 - val_accuracy: 0.5476\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.53571 to 0.54762, saving model to dog_breed_classifier_model.h5\n",
            "Epoch 16/150\n",
            "24/24 [==============================] - 9s 367ms/step - loss: 0.3022 - accuracy: 0.9444 - val_loss: 1.5395 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.54762 to 0.57143, saving model to dog_breed_classifier_model.h5\n",
            "Epoch 17/150\n",
            "24/24 [==============================] - 9s 365ms/step - loss: 0.2966 - accuracy: 0.9144 - val_loss: 1.6199 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.57143\n",
            "Epoch 18/150\n",
            "24/24 [==============================] - 9s 368ms/step - loss: 0.1840 - accuracy: 0.9654 - val_loss: 1.5676 - val_accuracy: 0.5595\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.57143\n",
            "Epoch 19/150\n",
            "24/24 [==============================] - 9s 366ms/step - loss: 0.1761 - accuracy: 0.9586 - val_loss: 1.7114 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.57143\n",
            "Epoch 20/150\n",
            "24/24 [==============================] - 9s 368ms/step - loss: 0.1627 - accuracy: 0.9568 - val_loss: 1.7209 - val_accuracy: 0.5357\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.57143\n",
            "Epoch 21/150\n",
            "24/24 [==============================] - 9s 369ms/step - loss: 0.1129 - accuracy: 0.9697 - val_loss: 1.8393 - val_accuracy: 0.5476\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.57143\n",
            "Epoch 22/150\n",
            "24/24 [==============================] - 9s 371ms/step - loss: 0.0828 - accuracy: 0.9754 - val_loss: 1.7315 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.57143\n",
            "Epoch 23/150\n",
            "24/24 [==============================] - 9s 371ms/step - loss: 0.1113 - accuracy: 0.9757 - val_loss: 1.6248 - val_accuracy: 0.5119\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.57143\n",
            "Epoch 24/150\n",
            "24/24 [==============================] - 9s 373ms/step - loss: 0.0928 - accuracy: 0.9758 - val_loss: 1.5717 - val_accuracy: 0.5595\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.57143\n",
            "Epoch 25/150\n",
            "24/24 [==============================] - 9s 372ms/step - loss: 0.0573 - accuracy: 0.9899 - val_loss: 1.6219 - val_accuracy: 0.5595\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.57143\n",
            "Epoch 26/150\n",
            "24/24 [==============================] - 9s 375ms/step - loss: 0.0731 - accuracy: 0.9724 - val_loss: 2.0325 - val_accuracy: 0.4762\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.57143\n",
            "Epoch 27/150\n",
            "24/24 [==============================] - 9s 368ms/step - loss: 0.1076 - accuracy: 0.9650 - val_loss: 1.9043 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.57143\n",
            "Epoch 28/150\n",
            "24/24 [==============================] - 9s 369ms/step - loss: 0.0879 - accuracy: 0.9814 - val_loss: 2.1790 - val_accuracy: 0.4643\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.57143\n",
            "Epoch 29/150\n",
            "24/24 [==============================] - 9s 372ms/step - loss: 0.1093 - accuracy: 0.9739 - val_loss: 2.8138 - val_accuracy: 0.4286\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.57143\n",
            "Epoch 30/150\n",
            "24/24 [==============================] - 9s 369ms/step - loss: 0.2016 - accuracy: 0.9601 - val_loss: 3.4615 - val_accuracy: 0.3333\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.57143\n",
            "Epoch 31/150\n",
            "24/24 [==============================] - 9s 369ms/step - loss: 0.2208 - accuracy: 0.9430 - val_loss: 2.6450 - val_accuracy: 0.4643\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.57143\n",
            "Epoch 32/150\n",
            "24/24 [==============================] - 9s 373ms/step - loss: 0.1535 - accuracy: 0.9618 - val_loss: 6.8650 - val_accuracy: 0.4286\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.57143\n",
            "Epoch 33/150\n",
            "24/24 [==============================] - 9s 368ms/step - loss: 0.1754 - accuracy: 0.9578 - val_loss: 4.7932 - val_accuracy: 0.3929\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.57143\n",
            "Epoch 34/150\n",
            "24/24 [==============================] - 9s 371ms/step - loss: 0.2083 - accuracy: 0.9408 - val_loss: 6.7496 - val_accuracy: 0.4405\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.57143\n",
            "Epoch 35/150\n",
            "24/24 [==============================] - 9s 371ms/step - loss: 0.1697 - accuracy: 0.9734 - val_loss: 3.0835 - val_accuracy: 0.4405\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.57143\n",
            "Epoch 36/150\n",
            "24/24 [==============================] - 9s 369ms/step - loss: 0.1759 - accuracy: 0.9554 - val_loss: 3.7180 - val_accuracy: 0.3929\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.57143\n",
            "Epoch 37/150\n",
            "24/24 [==============================] - 9s 372ms/step - loss: 0.1124 - accuracy: 0.9704 - val_loss: 6.0310 - val_accuracy: 0.2976\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.57143\n",
            "Epoch 38/150\n",
            "24/24 [==============================] - 9s 370ms/step - loss: 0.4763 - accuracy: 0.9026 - val_loss: 2.1280 - val_accuracy: 0.4643\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.57143\n",
            "Epoch 39/150\n",
            "24/24 [==============================] - 9s 370ms/step - loss: 0.3947 - accuracy: 0.9139 - val_loss: 5.3300 - val_accuracy: 0.3690\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.57143\n",
            "Epoch 40/150\n",
            "24/24 [==============================] - 9s 369ms/step - loss: 0.3712 - accuracy: 0.9043 - val_loss: 3.3051 - val_accuracy: 0.2619\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.57143\n",
            "Epoch 41/150\n",
            "24/24 [==============================] - 9s 369ms/step - loss: 0.3187 - accuracy: 0.9202 - val_loss: 10.5178 - val_accuracy: 0.3095\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.57143\n",
            "Epoch 42/150\n",
            "24/24 [==============================] - 9s 368ms/step - loss: 0.2321 - accuracy: 0.9479 - val_loss: 7.4935 - val_accuracy: 0.3214\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.57143\n",
            "Epoch 43/150\n",
            "24/24 [==============================] - 9s 369ms/step - loss: 0.5946 - accuracy: 0.8811 - val_loss: 4.4606 - val_accuracy: 0.2262\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.57143\n",
            "Epoch 44/150\n",
            "24/24 [==============================] - 9s 367ms/step - loss: 0.6286 - accuracy: 0.8223 - val_loss: 8.0390 - val_accuracy: 0.2143\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.57143\n",
            "Epoch 45/150\n",
            "24/24 [==============================] - 9s 373ms/step - loss: 0.3855 - accuracy: 0.9101 - val_loss: 8.7574 - val_accuracy: 0.1429\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.57143\n",
            "Epoch 46/150\n",
            "24/24 [==============================] - 9s 370ms/step - loss: 0.7711 - accuracy: 0.8074 - val_loss: 49.0958 - val_accuracy: 0.1905\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.57143\n",
            "Epoch 47/150\n",
            "24/24 [==============================] - 9s 369ms/step - loss: 0.7868 - accuracy: 0.7888 - val_loss: 16.1572 - val_accuracy: 0.0714\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.57143\n",
            "Epoch 48/150\n",
            "24/24 [==============================] - 9s 369ms/step - loss: 0.9919 - accuracy: 0.7243 - val_loss: 36.1880 - val_accuracy: 0.1667\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.57143\n",
            "Epoch 49/150\n",
            "24/24 [==============================] - 9s 369ms/step - loss: 0.4643 - accuracy: 0.9112 - val_loss: 10.2192 - val_accuracy: 0.1429\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.57143\n",
            "Epoch 50/150\n",
            "24/24 [==============================] - 9s 369ms/step - loss: 0.5730 - accuracy: 0.8588 - val_loss: 8.2786 - val_accuracy: 0.2857\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.57143\n",
            "Epoch 51/150\n",
            "24/24 [==============================] - 9s 369ms/step - loss: 0.6045 - accuracy: 0.8592 - val_loss: 19.9197 - val_accuracy: 0.0714\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.57143\n",
            "Epoch 52/150\n",
            "24/24 [==============================] - 9s 368ms/step - loss: 1.3149 - accuracy: 0.6595 - val_loss: 147.8226 - val_accuracy: 0.0595\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.57143\n",
            "Epoch 53/150\n",
            "24/24 [==============================] - 9s 370ms/step - loss: 1.1199 - accuracy: 0.6924 - val_loss: 63.5322 - val_accuracy: 0.0833\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.57143\n",
            "Epoch 54/150\n",
            "24/24 [==============================] - 9s 369ms/step - loss: 1.0875 - accuracy: 0.7014 - val_loss: 2413.4487 - val_accuracy: 0.0595\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.57143\n",
            "Epoch 55/150\n",
            "24/24 [==============================] - 9s 369ms/step - loss: 0.7772 - accuracy: 0.7866 - val_loss: 482.7773 - val_accuracy: 0.0595\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.57143\n",
            "Epoch 56/150\n",
            "24/24 [==============================] - 9s 370ms/step - loss: 1.4477 - accuracy: 0.5622 - val_loss: 5698.5088 - val_accuracy: 0.0952\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.57143\n",
            "Epoch 57/150\n",
            "24/24 [==============================] - 9s 369ms/step - loss: 0.9723 - accuracy: 0.7030 - val_loss: 118.0687 - val_accuracy: 0.0714\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.57143\n",
            "Epoch 58/150\n",
            "24/24 [==============================] - 9s 370ms/step - loss: 1.2361 - accuracy: 0.6875 - val_loss: 13.2687 - val_accuracy: 0.0357\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.57143\n",
            "Epoch 59/150\n",
            "24/24 [==============================] - 9s 369ms/step - loss: 1.5007 - accuracy: 0.5641 - val_loss: 4.6104 - val_accuracy: 0.1190\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.57143\n",
            "Epoch 60/150\n",
            "24/24 [==============================] - 9s 368ms/step - loss: 1.3294 - accuracy: 0.5962 - val_loss: 3653.9739 - val_accuracy: 0.0595\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.57143\n",
            "Epoch 61/150\n",
            "24/24 [==============================] - 9s 369ms/step - loss: 1.3099 - accuracy: 0.6425 - val_loss: 14.0459 - val_accuracy: 0.1071\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.57143\n",
            "Epoch 62/150\n",
            "24/24 [==============================] - 9s 368ms/step - loss: 1.0155 - accuracy: 0.7092 - val_loss: 37.3648 - val_accuracy: 0.0357\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.57143\n",
            "Epoch 63/150\n",
            "24/24 [==============================] - 9s 369ms/step - loss: 1.6316 - accuracy: 0.5106 - val_loss: 1118.1418 - val_accuracy: 0.0595\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.57143\n",
            "Epoch 64/150\n",
            "24/24 [==============================] - 9s 368ms/step - loss: 1.4276 - accuracy: 0.5792 - val_loss: 731.3066 - val_accuracy: 0.0595\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.57143\n",
            "Epoch 65/150\n",
            "24/24 [==============================] - 9s 368ms/step - loss: 1.2395 - accuracy: 0.6689 - val_loss: 22198.4121 - val_accuracy: 0.0595\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.57143\n",
            "Epoch 66/150\n",
            "24/24 [==============================] - 9s 367ms/step - loss: 1.9950 - accuracy: 0.3876 - val_loss: 444.2440 - val_accuracy: 0.0595\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.57143\n",
            "Epoch 67/150\n",
            "24/24 [==============================] - 9s 368ms/step - loss: 1.9956 - accuracy: 0.2918 - val_loss: 145.7523 - val_accuracy: 0.0357\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.57143\n",
            "Epoch 68/150\n",
            "24/24 [==============================] - 9s 367ms/step - loss: 1.9016 - accuracy: 0.3551 - val_loss: 3.6065 - val_accuracy: 0.1071\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.57143\n",
            "Epoch 69/150\n",
            "24/24 [==============================] - 9s 368ms/step - loss: 1.8497 - accuracy: 0.3935 - val_loss: 2045.0714 - val_accuracy: 0.0595\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.57143\n",
            "Epoch 70/150\n",
            "24/24 [==============================] - 9s 368ms/step - loss: 2.0470 - accuracy: 0.3002 - val_loss: 2.7243 - val_accuracy: 0.1071\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.57143\n",
            "Epoch 71/150\n",
            "24/24 [==============================] - 9s 367ms/step - loss: 1.9539 - accuracy: 0.3143 - val_loss: 5.7913 - val_accuracy: 0.0476\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.57143\n",
            "Epoch 72/150\n",
            "24/24 [==============================] - 9s 366ms/step - loss: 2.3407 - accuracy: 0.2077 - val_loss: 2.4035 - val_accuracy: 0.0952\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.57143\n",
            "Epoch 73/150\n",
            "24/24 [==============================] - 9s 365ms/step - loss: 2.2520 - accuracy: 0.1774 - val_loss: 2.3562 - val_accuracy: 0.0595\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.57143\n",
            "Epoch 74/150\n",
            "24/24 [==============================] - 9s 366ms/step - loss: 2.2735 - accuracy: 0.1755 - val_loss: 2.3556 - val_accuracy: 0.0595\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.57143\n",
            "Epoch 75/150\n",
            "24/24 [==============================] - 9s 367ms/step - loss: 2.2751 - accuracy: 0.1578 - val_loss: 2.3663 - val_accuracy: 0.0952\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.57143\n",
            "Epoch 76/150\n",
            "24/24 [==============================] - 9s 368ms/step - loss: 2.2612 - accuracy: 0.1636 - val_loss: 2.3341 - val_accuracy: 0.0952\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.57143\n",
            "Epoch 77/150\n",
            "24/24 [==============================] - 9s 365ms/step - loss: 2.2650 - accuracy: 0.1728 - val_loss: 2.4520 - val_accuracy: 0.0595\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.57143\n",
            "Epoch 78/150\n",
            "24/24 [==============================] - 9s 364ms/step - loss: 2.2693 - accuracy: 0.1820 - val_loss: 268.0822 - val_accuracy: 0.0833\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.57143\n",
            "Epoch 79/150\n",
            "24/24 [==============================] - 9s 362ms/step - loss: 2.2818 - accuracy: 0.1332 - val_loss: 2.2665 - val_accuracy: 0.1786\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.57143\n",
            "Epoch 80/150\n",
            "24/24 [==============================] - 9s 365ms/step - loss: 2.2896 - accuracy: 0.1534 - val_loss: 2.2749 - val_accuracy: 0.1786\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.57143\n",
            "Epoch 81/150\n",
            "24/24 [==============================] - 9s 360ms/step - loss: 2.3006 - accuracy: 0.1435 - val_loss: 2.2826 - val_accuracy: 0.1786\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.57143\n",
            "Epoch 82/150\n",
            "24/24 [==============================] - 9s 354ms/step - loss: 2.3021 - accuracy: 0.1383 - val_loss: 2.2934 - val_accuracy: 0.0952\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.57143\n",
            "Epoch 83/150\n",
            "24/24 [==============================] - 9s 350ms/step - loss: 2.3022 - accuracy: 0.1421 - val_loss: 2.2705 - val_accuracy: 0.1786\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.57143\n",
            "Epoch 84/150\n",
            "24/24 [==============================] - 9s 351ms/step - loss: 2.3050 - accuracy: 0.1413 - val_loss: 2.3296 - val_accuracy: 0.0952\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.57143\n",
            "Epoch 85/150\n",
            "24/24 [==============================] - 9s 351ms/step - loss: 2.3050 - accuracy: 0.1236 - val_loss: 2.2950 - val_accuracy: 0.1786\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.57143\n",
            "Epoch 86/150\n",
            "24/24 [==============================] - 9s 352ms/step - loss: 2.3071 - accuracy: 0.1303 - val_loss: 2.2575 - val_accuracy: 0.1786\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.57143\n",
            "Epoch 87/150\n",
            "24/24 [==============================] - 9s 350ms/step - loss: 2.3059 - accuracy: 0.1362 - val_loss: 2.3391 - val_accuracy: 0.0952\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.57143\n",
            "Epoch 88/150\n",
            "24/24 [==============================] - 8s 352ms/step - loss: 2.3417 - accuracy: 0.0877 - val_loss: 2.2804 - val_accuracy: 0.1786\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.57143\n",
            "Epoch 89/150\n",
            "24/24 [==============================] - 8s 350ms/step - loss: 2.3284 - accuracy: 0.0952 - val_loss: 2.3060 - val_accuracy: 0.1786\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.57143\n",
            "Epoch 90/150\n",
            "24/24 [==============================] - 9s 351ms/step - loss: 2.3184 - accuracy: 0.0978 - val_loss: 2.2984 - val_accuracy: 0.1786\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.57143\n",
            "Epoch 91/150\n",
            "24/24 [==============================] - 8s 350ms/step - loss: 2.3121 - accuracy: 0.1195 - val_loss: 2.4107 - val_accuracy: 0.0595\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.57143\n",
            "Epoch 92/150\n",
            "24/24 [==============================] - 9s 350ms/step - loss: 2.3642 - accuracy: 0.1321 - val_loss: 2.3217 - val_accuracy: 0.0952\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.57143\n",
            "Epoch 93/150\n",
            "24/24 [==============================] - 8s 350ms/step - loss: 2.3217 - accuracy: 0.1041 - val_loss: 2.3325 - val_accuracy: 0.1786\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.57143\n",
            "Epoch 94/150\n",
            "24/24 [==============================] - 9s 352ms/step - loss: 2.4232 - accuracy: 0.0940 - val_loss: 2.2968 - val_accuracy: 0.1786\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.57143\n",
            "Epoch 95/150\n",
            "24/24 [==============================] - 8s 350ms/step - loss: 2.3742 - accuracy: 0.0928 - val_loss: 2.4483 - val_accuracy: 0.1786\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.57143\n",
            "Epoch 96/150\n",
            "24/24 [==============================] - 9s 354ms/step - loss: 2.3674 - accuracy: 0.1148 - val_loss: 2.5635 - val_accuracy: 0.1190\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.57143\n",
            "Epoch 97/150\n",
            "24/24 [==============================] - 9s 353ms/step - loss: 2.4027 - accuracy: 0.1143 - val_loss: 2.3946 - val_accuracy: 0.0952\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.57143\n",
            "Epoch 98/150\n",
            "24/24 [==============================] - 8s 348ms/step - loss: 2.3727 - accuracy: 0.1340 - val_loss: 2.4215 - val_accuracy: 0.0595\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.57143\n",
            "Epoch 99/150\n",
            "24/24 [==============================] - 8s 351ms/step - loss: 2.4120 - accuracy: 0.0998 - val_loss: 2.3472 - val_accuracy: 0.1786\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.57143\n",
            "Epoch 100/150\n",
            "24/24 [==============================] - 9s 351ms/step - loss: 2.3837 - accuracy: 0.1059 - val_loss: 2.4194 - val_accuracy: 0.0952\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.57143\n",
            "Epoch 101/150\n",
            "24/24 [==============================] - 8s 348ms/step - loss: 2.3786 - accuracy: 0.1389 - val_loss: 2.4431 - val_accuracy: 0.0357\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.57143\n",
            "Epoch 102/150\n",
            "24/24 [==============================] - 9s 352ms/step - loss: 2.4686 - accuracy: 0.1262 - val_loss: 2.6053 - val_accuracy: 0.0595\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.57143\n",
            "Epoch 103/150\n",
            "24/24 [==============================] - 8s 348ms/step - loss: 2.4756 - accuracy: 0.1325 - val_loss: 2.3466 - val_accuracy: 0.1071\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.57143\n",
            "Epoch 104/150\n",
            "24/24 [==============================] - 8s 349ms/step - loss: 2.4601 - accuracy: 0.1088 - val_loss: 2.3808 - val_accuracy: 0.0952\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.57143\n",
            "Epoch 105/150\n",
            "24/24 [==============================] - 9s 351ms/step - loss: 2.4673 - accuracy: 0.1364 - val_loss: 2.5413 - val_accuracy: 0.1190\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.57143\n",
            "Epoch 106/150\n",
            "24/24 [==============================] - 8s 350ms/step - loss: 2.6001 - accuracy: 0.1055 - val_loss: 2.7460 - val_accuracy: 0.1190\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.57143\n",
            "Epoch 107/150\n",
            "24/24 [==============================] - 8s 350ms/step - loss: 2.6405 - accuracy: 0.1302 - val_loss: 2.5046 - val_accuracy: 0.1786\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.57143\n",
            "Epoch 108/150\n",
            "24/24 [==============================] - 9s 348ms/step - loss: 2.6648 - accuracy: 0.1248 - val_loss: 2.5976 - val_accuracy: 0.1071\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.57143\n",
            "Epoch 109/150\n",
            "24/24 [==============================] - 8s 349ms/step - loss: 2.6487 - accuracy: 0.1064 - val_loss: 3.1277 - val_accuracy: 0.0952\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.57143\n",
            "Epoch 110/150\n",
            "24/24 [==============================] - 8s 353ms/step - loss: 2.7060 - accuracy: 0.1084 - val_loss: 2.4148 - val_accuracy: 0.0952\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.57143\n",
            "Epoch 111/150\n",
            "24/24 [==============================] - 8s 349ms/step - loss: 2.5945 - accuracy: 0.1156 - val_loss: 2.7986 - val_accuracy: 0.0595\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.57143\n",
            "Epoch 112/150\n",
            "24/24 [==============================] - 8s 348ms/step - loss: 3.0483 - accuracy: 0.0945 - val_loss: 2.9338 - val_accuracy: 0.1071\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.57143\n",
            "Epoch 113/150\n",
            "24/24 [==============================] - 8s 348ms/step - loss: 2.8874 - accuracy: 0.0926 - val_loss: 3.0159 - val_accuracy: 0.0952\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.57143\n",
            "Epoch 114/150\n",
            "24/24 [==============================] - 9s 352ms/step - loss: 2.9864 - accuracy: 0.1238 - val_loss: 3.4094 - val_accuracy: 0.0357\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.57143\n",
            "Epoch 115/150\n",
            "24/24 [==============================] - 8s 349ms/step - loss: 3.2037 - accuracy: 0.0957 - val_loss: 3.0973 - val_accuracy: 0.1786\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.57143\n",
            "Epoch 116/150\n",
            "24/24 [==============================] - 8s 350ms/step - loss: 3.0252 - accuracy: 0.1297 - val_loss: 3.1890 - val_accuracy: 0.1071\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.57143\n",
            "Epoch 117/150\n",
            "24/24 [==============================] - 8s 348ms/step - loss: 3.0400 - accuracy: 0.1223 - val_loss: 2.9604 - val_accuracy: 0.1786\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.57143\n",
            "Epoch 118/150\n",
            "24/24 [==============================] - 9s 354ms/step - loss: 4.0586 - accuracy: 0.1193 - val_loss: 6.9719 - val_accuracy: 0.0595\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.57143\n",
            "Epoch 119/150\n",
            "24/24 [==============================] - 9s 353ms/step - loss: 7.4904 - accuracy: 0.0960 - val_loss: 8.4822 - val_accuracy: 0.0952\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.57143\n",
            "Epoch 120/150\n",
            "24/24 [==============================] - 8s 348ms/step - loss: 7.2198 - accuracy: 0.0842 - val_loss: 6.7601 - val_accuracy: 0.0952\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.57143\n",
            "Epoch 121/150\n",
            "24/24 [==============================] - 8s 347ms/step - loss: 7.7405 - accuracy: 0.1144 - val_loss: 7.9413 - val_accuracy: 0.1548\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.57143\n",
            "Epoch 122/150\n",
            "24/24 [==============================] - 8s 349ms/step - loss: 8.0177 - accuracy: 0.0902 - val_loss: 8.8205 - val_accuracy: 0.1071\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.57143\n",
            "Epoch 123/150\n",
            "24/24 [==============================] - 8s 349ms/step - loss: 8.6616 - accuracy: 0.1121 - val_loss: 10.4432 - val_accuracy: 0.0595\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.57143\n",
            "Epoch 124/150\n",
            "24/24 [==============================] - 8s 349ms/step - loss: 10.3725 - accuracy: 0.0951 - val_loss: 11.0478 - val_accuracy: 0.0595\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.57143\n",
            "Epoch 125/150\n",
            "24/24 [==============================] - 8s 347ms/step - loss: 11.2193 - accuracy: 0.1121 - val_loss: 9.4040 - val_accuracy: 0.0952\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.57143\n",
            "Epoch 126/150\n",
            "24/24 [==============================] - 9s 351ms/step - loss: 16.7474 - accuracy: 0.0757 - val_loss: 17.3361 - val_accuracy: 0.1786\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.57143\n",
            "Epoch 127/150\n",
            "24/24 [==============================] - 8s 348ms/step - loss: 18.0549 - accuracy: 0.1106 - val_loss: 14.3372 - val_accuracy: 0.1190\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.57143\n",
            "Epoch 128/150\n",
            "24/24 [==============================] - 8s 355ms/step - loss: 16.1689 - accuracy: 0.0892 - val_loss: 14.9842 - val_accuracy: 0.0952\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.57143\n",
            "Epoch 129/150\n",
            "24/24 [==============================] - 8s 352ms/step - loss: 17.9945 - accuracy: 0.1010 - val_loss: 10.5604 - val_accuracy: 0.0952\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.57143\n",
            "Epoch 130/150\n",
            "24/24 [==============================] - 8s 348ms/step - loss: 17.1882 - accuracy: 0.1377 - val_loss: 19.6998 - val_accuracy: 0.1190\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.57143\n",
            "Epoch 131/150\n",
            "24/24 [==============================] - 9s 353ms/step - loss: 23.0046 - accuracy: 0.0870 - val_loss: 21.4508 - val_accuracy: 0.1786\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.57143\n",
            "Epoch 132/150\n",
            "24/24 [==============================] - 8s 349ms/step - loss: 30.4502 - accuracy: 0.0901 - val_loss: 44.1689 - val_accuracy: 0.1786\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.57143\n",
            "Epoch 133/150\n",
            "24/24 [==============================] - 9s 352ms/step - loss: 44.0239 - accuracy: 0.1117 - val_loss: 60.3169 - val_accuracy: 0.0952\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.57143\n",
            "Epoch 134/150\n",
            "24/24 [==============================] - 9s 353ms/step - loss: 53.7884 - accuracy: 0.1083 - val_loss: 32.4990 - val_accuracy: 0.0357\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.57143\n",
            "Epoch 135/150\n",
            "24/24 [==============================] - 8s 355ms/step - loss: 49.6836 - accuracy: 0.0819 - val_loss: 52.4324 - val_accuracy: 0.1190\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.57143\n",
            "Epoch 136/150\n",
            "24/24 [==============================] - 8s 350ms/step - loss: 59.0499 - accuracy: 0.1019 - val_loss: 105.6678 - val_accuracy: 0.1786\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.57143\n",
            "Epoch 137/150\n",
            "24/24 [==============================] - 8s 350ms/step - loss: 63.0592 - accuracy: 0.1430 - val_loss: 55.9440 - val_accuracy: 0.0952\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.57143\n",
            "Epoch 138/150\n",
            "24/24 [==============================] - 8s 349ms/step - loss: 66.2025 - accuracy: 0.1039 - val_loss: 79.0338 - val_accuracy: 0.0595\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.57143\n",
            "Epoch 139/150\n",
            "24/24 [==============================] - 8s 350ms/step - loss: 73.6766 - accuracy: 0.1035 - val_loss: 60.7022 - val_accuracy: 0.0595\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.57143\n",
            "Epoch 140/150\n",
            "24/24 [==============================] - 8s 347ms/step - loss: 55.9155 - accuracy: 0.1117 - val_loss: 65.2666 - val_accuracy: 0.1786\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.57143\n",
            "Epoch 141/150\n",
            "24/24 [==============================] - 9s 351ms/step - loss: 97.7710 - accuracy: 0.1109 - val_loss: 91.8836 - val_accuracy: 0.0952\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.57143\n",
            "Epoch 142/150\n",
            "24/24 [==============================] - 9s 353ms/step - loss: 111.2321 - accuracy: 0.1114 - val_loss: 127.2057 - val_accuracy: 0.1786\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.57143\n",
            "Epoch 143/150\n",
            "24/24 [==============================] - 8s 349ms/step - loss: 141.6348 - accuracy: 0.1323 - val_loss: 143.2561 - val_accuracy: 0.0952\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.57143\n",
            "Epoch 144/150\n",
            "24/24 [==============================] - 8s 349ms/step - loss: 140.9812 - accuracy: 0.1418 - val_loss: 176.5835 - val_accuracy: 0.0952\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.57143\n",
            "Epoch 145/150\n",
            "24/24 [==============================] - 8s 349ms/step - loss: 172.7164 - accuracy: 0.0978 - val_loss: 145.9384 - val_accuracy: 0.0952\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.57143\n",
            "Epoch 146/150\n",
            "24/24 [==============================] - 8s 349ms/step - loss: 139.9818 - accuracy: 0.1062 - val_loss: 197.7095 - val_accuracy: 0.0595\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.57143\n",
            "Epoch 147/150\n",
            "24/24 [==============================] - 9s 348ms/step - loss: 166.1027 - accuracy: 0.1031 - val_loss: 236.8260 - val_accuracy: 0.1071\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.57143\n",
            "Epoch 148/150\n",
            "24/24 [==============================] - 8s 346ms/step - loss: 206.1297 - accuracy: 0.1225 - val_loss: 90.6076 - val_accuracy: 0.1071\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.57143\n",
            "Epoch 149/150\n",
            "24/24 [==============================] - 8s 348ms/step - loss: 156.3300 - accuracy: 0.1141 - val_loss: 179.7494 - val_accuracy: 0.1548\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.57143\n",
            "Epoch 150/150\n",
            "24/24 [==============================] - 8s 347ms/step - loss: 192.7537 - accuracy: 0.1168 - val_loss: 177.1735 - val_accuracy: 0.0357\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.57143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHSVn0QSTck_",
        "outputId": "f0aca5a7-041b-4d78-dd4d-ff854324b419"
      },
      "source": [
        "val_acc= max(history.history['val_accuracy'])\r\n",
        "val_accuracy= history.history['val_accuracy']\r\n",
        "index=val_accuracy.index(val_acc)\r\n",
        "lrs= history.history['lr']\r\n",
        "count=0\r\n",
        "for i in lrs:\r\n",
        "  if count==index: \r\n",
        "    lr=i\r\n",
        "    break\r\n",
        "  count+=1\r\n",
        "print(lr)\r\n",
        "print(val_acc)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5.6234134e-05\n",
            "0.5714285969734192\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "x1beZfhATciY",
        "outputId": "74808f4e-be96-4c68-bcde-4882b4dccc56"
      },
      "source": [
        "lrs= 1e-5*(10**(np.arange(50)/20))\r\n",
        "plt.semilogx(lrs, history.history[\"val_accuracy\"], label='Validation Accuracy')\r\n",
        "plt.legend(loc='best')\r\n",
        "plt.grid(True)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64FTryG5S3d-"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-KVsw6pYlnK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8eb7486-fbe1-40a4-fff5-df775c0c34ea"
      },
      "source": [
        "keras.backend.clear_session()\r\n",
        "\r\n",
        "model.load_weights('dog_breed_classifier_model.h5')\r\n",
        "model.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50 (Functional)        (None, 7, 7, 2048)        23587712  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 23,858,890\n",
            "Trainable params: 23,805,770\n",
            "Non-trainable params: 53,120\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HudNnU9JaLX0"
      },
      "source": [
        "num_layers= 6\r\n",
        "for Layers in model.layers[-num_layers:]:\r\n",
        "  Layers.trainable= True"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JolhxmbXap6Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ea2b3ff-e75d-42a0-f50b-60d2a832415a"
      },
      "source": [
        "# STEP_SIZE_TRAIN = int(np.ceil(train_generator.n / train_generator.batch_size))\r\n",
        "# STEP_SIZE_VAL = int(np.ceil(validation_generator.n / validation_generator.batch_size))\r\n",
        "\r\n",
        "# print(\"Train step size:\", STEP_SIZE_TRAIN)\r\n",
        "# print(\"Validation step size:\", STEP_SIZE_VAL)\r\n",
        "\r\n",
        "# train_generator.reset()\r\n",
        "# validation_generator.reset()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train step size: 24\n",
            "Validation step size: 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFk2O7xEaWpw"
      },
      "source": [
        "model.compile(\r\n",
        "    optimizer= keras.optimizers.Adam(learning_rate=lr),\r\n",
        "    loss= keras.losses.CategoricalCrossentropy(),\r\n",
        "    metrics=['accuracy']\r\n",
        ")"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7nxU6ck7p2b"
      },
      "source": [
        "# # a check point callback to save our best weights\r\n",
        "checkpoint = keras.callbacks.ModelCheckpoint('model.h5', monitor='val_accuracy', \r\n",
        "                                             verbose=1, save_best_only=True, \r\n",
        "                                             mode='max') #save_weights_only=True)\r\n",
        "\r\n",
        "# # a reducing lr callback to reduce lr when val_accuracy doesn't increase\r\n",
        "# reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.4,\r\n",
        "#                                               patience=2, verbose=1, mode='auto',\r\n",
        "#                                               min_delta=0.001, cooldown=2, min_lr=1e-5)\r\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSjxEGm6aWm2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57cbd80f-aa3c-4ed5-dc65-5e0e60545447"
      },
      "source": [
        "history = model.fit_generator(train_generator,\r\n",
        "                              # steps_per_epoch=STEP_SIZE_TRAIN,\r\n",
        "                              validation_data=validation_generator, verbose=1,\r\n",
        "                              # validation_steps=STEP_SIZE_VAL,\r\n",
        "                              epochs=50, callbacks=[checkpoint])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "24/24 [==============================] - 15s 426ms/step - loss: 0.2676 - accuracy: 0.9437 - val_loss: 1.6613 - val_accuracy: 0.5476\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.54762, saving model to model.h5\n",
            "Epoch 2/50\n",
            "24/24 [==============================] - 9s 388ms/step - loss: 0.2017 - accuracy: 0.9516 - val_loss: 1.6453 - val_accuracy: 0.5476\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.54762\n",
            "Epoch 3/50\n",
            "24/24 [==============================] - 9s 379ms/step - loss: 0.2063 - accuracy: 0.9410 - val_loss: 1.6714 - val_accuracy: 0.5476\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.54762\n",
            "Epoch 4/50\n",
            "24/24 [==============================] - 9s 369ms/step - loss: 0.1566 - accuracy: 0.9582 - val_loss: 1.6101 - val_accuracy: 0.5476\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.54762\n",
            "Epoch 5/50\n",
            "24/24 [==============================] - 9s 364ms/step - loss: 0.1347 - accuracy: 0.9658 - val_loss: 1.6072 - val_accuracy: 0.5476\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.54762\n",
            "Epoch 6/50\n",
            "24/24 [==============================] - 9s 362ms/step - loss: 0.1273 - accuracy: 0.9641 - val_loss: 1.5732 - val_accuracy: 0.5595\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.54762 to 0.55952, saving model to model.h5\n",
            "Epoch 7/50\n",
            "24/24 [==============================] - 9s 361ms/step - loss: 0.0867 - accuracy: 0.9782 - val_loss: 1.6423 - val_accuracy: 0.5476\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.55952\n",
            "Epoch 8/50\n",
            "24/24 [==============================] - 9s 362ms/step - loss: 0.1037 - accuracy: 0.9709 - val_loss: 1.6214 - val_accuracy: 0.5357\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.55952\n",
            "Epoch 9/50\n",
            "24/24 [==============================] - 9s 368ms/step - loss: 0.1039 - accuracy: 0.9743 - val_loss: 1.6594 - val_accuracy: 0.5238\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.55952\n",
            "Epoch 10/50\n",
            "24/24 [==============================] - 9s 372ms/step - loss: 0.0716 - accuracy: 0.9808 - val_loss: 1.6887 - val_accuracy: 0.5357\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.55952\n",
            "Epoch 11/50\n",
            "24/24 [==============================] - 9s 373ms/step - loss: 0.0598 - accuracy: 0.9848 - val_loss: 1.7589 - val_accuracy: 0.5357\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.55952\n",
            "Epoch 12/50\n",
            "24/24 [==============================] - 9s 372ms/step - loss: 0.0601 - accuracy: 0.9809 - val_loss: 1.8476 - val_accuracy: 0.5476\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.55952\n",
            "Epoch 13/50\n",
            "24/24 [==============================] - 9s 370ms/step - loss: 0.0482 - accuracy: 0.9938 - val_loss: 1.8384 - val_accuracy: 0.5238\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.55952\n",
            "Epoch 14/50\n",
            "24/24 [==============================] - 9s 368ms/step - loss: 0.0604 - accuracy: 0.9854 - val_loss: 1.8266 - val_accuracy: 0.5952\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.55952 to 0.59524, saving model to model.h5\n",
            "Epoch 15/50\n",
            "24/24 [==============================] - 9s 368ms/step - loss: 0.0552 - accuracy: 0.9800 - val_loss: 1.8482 - val_accuracy: 0.5476\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.59524\n",
            "Epoch 16/50\n",
            "24/24 [==============================] - 9s 368ms/step - loss: 0.0628 - accuracy: 0.9833 - val_loss: 1.8486 - val_accuracy: 0.5476\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.59524\n",
            "Epoch 17/50\n",
            "24/24 [==============================] - 9s 367ms/step - loss: 0.0552 - accuracy: 0.9878 - val_loss: 1.9196 - val_accuracy: 0.5595\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.59524\n",
            "Epoch 18/50\n",
            "24/24 [==============================] - 9s 367ms/step - loss: 0.0429 - accuracy: 0.9890 - val_loss: 2.0302 - val_accuracy: 0.5476\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.59524\n",
            "Epoch 19/50\n",
            "24/24 [==============================] - 9s 370ms/step - loss: 0.0337 - accuracy: 0.9936 - val_loss: 2.1181 - val_accuracy: 0.5476\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.59524\n",
            "Epoch 20/50\n",
            "24/24 [==============================] - 9s 369ms/step - loss: 0.0398 - accuracy: 0.9932 - val_loss: 2.2187 - val_accuracy: 0.5357\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.59524\n",
            "Epoch 21/50\n",
            "24/24 [==============================] - 9s 370ms/step - loss: 0.0598 - accuracy: 0.9824 - val_loss: 2.0507 - val_accuracy: 0.5833\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.59524\n",
            "Epoch 22/50\n",
            "24/24 [==============================] - 9s 369ms/step - loss: 0.0355 - accuracy: 0.9933 - val_loss: 1.9307 - val_accuracy: 0.5833\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.59524\n",
            "Epoch 23/50\n",
            "24/24 [==============================] - 9s 369ms/step - loss: 0.0597 - accuracy: 0.9794 - val_loss: 1.9111 - val_accuracy: 0.5952\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.59524\n",
            "Epoch 24/50\n",
            "24/24 [==============================] - 9s 367ms/step - loss: 0.0411 - accuracy: 0.9881 - val_loss: 2.1087 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.59524\n",
            "Epoch 25/50\n",
            "24/24 [==============================] - 9s 367ms/step - loss: 0.0407 - accuracy: 0.9876 - val_loss: 2.0477 - val_accuracy: 0.5952\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.59524\n",
            "Epoch 26/50\n",
            "24/24 [==============================] - 9s 367ms/step - loss: 0.0566 - accuracy: 0.9877 - val_loss: 2.0509 - val_accuracy: 0.5833\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.59524\n",
            "Epoch 27/50\n",
            "24/24 [==============================] - 9s 366ms/step - loss: 0.0312 - accuracy: 0.9904 - val_loss: 2.0587 - val_accuracy: 0.5952\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.59524\n",
            "Epoch 28/50\n",
            "24/24 [==============================] - 9s 367ms/step - loss: 0.0492 - accuracy: 0.9785 - val_loss: 2.1858 - val_accuracy: 0.6190\n",
            "\n",
            "Epoch 00028: val_accuracy improved from 0.59524 to 0.61905, saving model to model.h5\n",
            "Epoch 29/50\n",
            "24/24 [==============================] - 9s 367ms/step - loss: 0.0513 - accuracy: 0.9828 - val_loss: 2.2143 - val_accuracy: 0.6071\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.61905\n",
            "Epoch 30/50\n",
            "24/24 [==============================] - 9s 368ms/step - loss: 0.0187 - accuracy: 0.9950 - val_loss: 2.2564 - val_accuracy: 0.6071\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.61905\n",
            "Epoch 31/50\n",
            "24/24 [==============================] - 9s 368ms/step - loss: 0.0398 - accuracy: 0.9842 - val_loss: 2.2322 - val_accuracy: 0.5595\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.61905\n",
            "Epoch 32/50\n",
            "24/24 [==============================] - 9s 371ms/step - loss: 0.0208 - accuracy: 0.9965 - val_loss: 2.2215 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.61905\n",
            "Epoch 33/50\n",
            "24/24 [==============================] - 9s 371ms/step - loss: 0.0266 - accuracy: 0.9929 - val_loss: 2.2078 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.61905\n",
            "Epoch 34/50\n",
            "24/24 [==============================] - 9s 368ms/step - loss: 0.0161 - accuracy: 0.9947 - val_loss: 2.2558 - val_accuracy: 0.5833\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.61905\n",
            "Epoch 35/50\n",
            "24/24 [==============================] - 9s 368ms/step - loss: 0.0333 - accuracy: 0.9914 - val_loss: 2.2193 - val_accuracy: 0.5833\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.61905\n",
            "Epoch 36/50\n",
            "24/24 [==============================] - 9s 372ms/step - loss: 0.0190 - accuracy: 0.9974 - val_loss: 2.1234 - val_accuracy: 0.5833\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.61905\n",
            "Epoch 37/50\n",
            "24/24 [==============================] - 9s 369ms/step - loss: 0.0193 - accuracy: 0.9955 - val_loss: 2.0310 - val_accuracy: 0.5833\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.61905\n",
            "Epoch 38/50\n",
            "24/24 [==============================] - 9s 367ms/step - loss: 0.0253 - accuracy: 0.9965 - val_loss: 2.2726 - val_accuracy: 0.5595\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.61905\n",
            "Epoch 39/50\n",
            "24/24 [==============================] - 9s 367ms/step - loss: 0.0318 - accuracy: 0.9878 - val_loss: 2.3297 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.61905\n",
            "Epoch 40/50\n",
            "24/24 [==============================] - 9s 366ms/step - loss: 0.0241 - accuracy: 0.9933 - val_loss: 2.6225 - val_accuracy: 0.5833\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.61905\n",
            "Epoch 41/50\n",
            "24/24 [==============================] - 9s 368ms/step - loss: 0.0393 - accuracy: 0.9899 - val_loss: 2.5598 - val_accuracy: 0.6071\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.61905\n",
            "Epoch 42/50\n",
            "24/24 [==============================] - 9s 368ms/step - loss: 0.0238 - accuracy: 0.9955 - val_loss: 2.6957 - val_accuracy: 0.5833\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.61905\n",
            "Epoch 43/50\n",
            "24/24 [==============================] - 9s 367ms/step - loss: 0.0192 - accuracy: 0.9965 - val_loss: 2.6442 - val_accuracy: 0.5952\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.61905\n",
            "Epoch 44/50\n",
            "24/24 [==============================] - 9s 366ms/step - loss: 0.0352 - accuracy: 0.9892 - val_loss: 2.7282 - val_accuracy: 0.5476\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.61905\n",
            "Epoch 45/50\n",
            "24/24 [==============================] - 9s 373ms/step - loss: 0.0150 - accuracy: 0.9980 - val_loss: 2.5192 - val_accuracy: 0.5476\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.61905\n",
            "Epoch 46/50\n",
            "24/24 [==============================] - 9s 369ms/step - loss: 0.0184 - accuracy: 0.9984 - val_loss: 2.4078 - val_accuracy: 0.5357\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.61905\n",
            "Epoch 47/50\n",
            "24/24 [==============================] - 9s 369ms/step - loss: 0.0175 - accuracy: 0.9970 - val_loss: 2.2914 - val_accuracy: 0.5119\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.61905\n",
            "Epoch 48/50\n",
            "24/24 [==============================] - 9s 370ms/step - loss: 0.0272 - accuracy: 0.9931 - val_loss: 2.2276 - val_accuracy: 0.5238\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.61905\n",
            "Epoch 49/50\n",
            "24/24 [==============================] - 9s 371ms/step - loss: 0.0253 - accuracy: 0.9970 - val_loss: 2.1020 - val_accuracy: 0.5476\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.61905\n",
            "Epoch 50/50\n",
            "24/24 [==============================] - 9s 369ms/step - loss: 0.0293 - accuracy: 0.9971 - val_loss: 2.2236 - val_accuracy: 0.5595\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.61905\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4i3kZ3vaWkV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "c1b1a84d-2ba4-40ec-ba31-feb67c576698"
      },
      "source": [
        "plt.plot(history.history['accuracy'])\r\n",
        "plt.plot(history.history['val_accuracy'])\r\n",
        "plt.title('Model Accuracy')\r\n",
        "plt.ylabel('Accuracy')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.legend(['Train', 'Validation'], loc='best')\r\n",
        "plt.show()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vsmo_KLd1WNR"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwFCgI6Y1V7k"
      },
      "source": [
        "uploaded= files.upload()\r\n",
        "\r\n",
        "for fn in uploaded.keys():\r\n",
        "  # predict image\r\n",
        "  path='/content/' + fn\r\n",
        "  img= image.load_img(path, target_size=(300,300))\r\n",
        "  plt.axis('off')\r\n",
        "  plt.imshow(img)\r\n",
        "  plt.show()\r\n",
        "  x= image.img_to_array(img)\r\n",
        "  x= np.expand_dims(x, axis=0)\r\n",
        "  \r\n",
        "  images= np.vstack([x])\r\n",
        "  classes= model.predict(images, batch_size=10)\r\n",
        "  print(classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pKVKpP4vZFb"
      },
      "source": [
        "# Model Saving"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SMHYap_vdMr"
      },
      "source": [
        "model.save(\"dog_breed_model.h5\")"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHGyb4X2HdE8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}