{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dog Breed Identification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPJ9W349VCUNDp20xMoDE1V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/utkarsh0702/Tensorflow/blob/master/Dog_Breed_Identification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhB1lvCRmywn"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import os\r\n",
        "from tensorflow import keras\r\n",
        "import zipfile\r\n",
        "from google.colab import files\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from google.colab import files\r\n",
        "from tensorflow.keras.preprocessing import image\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6-U-nnlm-jU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c8e1027-6918-418b-e1c7-8189fbb8e881"
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\r\n",
        "if device_name != '/device:GPU:0':\r\n",
        "  raise SystemError('GPU device not found')\r\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hgpfs28YnH8P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f05722bc-d766-40dc-f40d-b773a6e19974"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvWwQeFbnH3V"
      },
      "source": [
        "local_zip= '/content/drive/My Drive/datasets/dog-breed-identification.zip'\r\n",
        "zip_ref= zipfile.ZipFile(local_zip, 'r')\r\n",
        "zip_ref.extractall('/content')\r\n",
        "zip_ref.close()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbbjgclGnHzJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "8fe2a1a1-c5f3-4ea5-a16b-ea32478cca2d"
      },
      "source": [
        "df= pd.read_csv('labels.csv')\r\n",
        "df"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>breed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
              "      <td>boston_bull</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
              "      <td>dingo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>001cdf01b096e06d78e9e5112d419397</td>\n",
              "      <td>pekinese</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n",
              "      <td>bluetick</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
              "      <td>golden_retriever</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10217</th>\n",
              "      <td>ffd25009d635cfd16e793503ac5edef0</td>\n",
              "      <td>borzoi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10218</th>\n",
              "      <td>ffd3f636f7f379c51ba3648a9ff8254f</td>\n",
              "      <td>dandie_dinmont</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10219</th>\n",
              "      <td>ffe2ca6c940cddfee68fa3cc6c63213f</td>\n",
              "      <td>airedale</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10220</th>\n",
              "      <td>ffe5f6d8e2bff356e9482a80a6e29aac</td>\n",
              "      <td>miniature_pinscher</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10221</th>\n",
              "      <td>fff43b07992508bc822f33d8ffd902ae</td>\n",
              "      <td>chesapeake_bay_retriever</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10222 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     id                     breed\n",
              "0      000bec180eb18c7604dcecc8fe0dba07               boston_bull\n",
              "1      001513dfcb2ffafc82cccf4d8bbaba97                     dingo\n",
              "2      001cdf01b096e06d78e9e5112d419397                  pekinese\n",
              "3      00214f311d5d2247d5dfe4fe24b2303d                  bluetick\n",
              "4      0021f9ceb3235effd7fcde7f7538ed62          golden_retriever\n",
              "...                                 ...                       ...\n",
              "10217  ffd25009d635cfd16e793503ac5edef0                    borzoi\n",
              "10218  ffd3f636f7f379c51ba3648a9ff8254f            dandie_dinmont\n",
              "10219  ffe2ca6c940cddfee68fa3cc6c63213f                  airedale\n",
              "10220  ffe5f6d8e2bff356e9482a80a6e29aac        miniature_pinscher\n",
              "10221  fff43b07992508bc822f33d8ffd902ae  chesapeake_bay_retriever\n",
              "\n",
              "[10222 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUkho0L_E6eU"
      },
      "source": [
        "**Choosing specific Dog Breeds**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "2QggSmxHE3mC",
        "outputId": "adc025cd-d329-470b-de43-ae6ba4bbf223"
      },
      "source": [
        "breeds=['beagle', 'chihuahua', 'doberman','french_bulldog', 'golden_retriever', 'malamute', 'pug', 'saint_bernard', 'scottish_deerhound','tibetan_mastiff']\r\n",
        "df1 = df.loc[df['breed'].apply(lambda x: any([k in x for k in breeds]))]\r\n",
        "df1.head(10)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>breed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
              "      <td>golden_retriever</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0042188c895a2f14ef64a918ed9c7b64</td>\n",
              "      <td>scottish_deerhound</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>008b1271ed1addaccf93783b39deab45</td>\n",
              "      <td>doberman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>00a366d4b4a9bbb6c8a63126697b7656</td>\n",
              "      <td>golden_retriever</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0100f55e4f0fe28f2c0465d3fc4b9897</td>\n",
              "      <td>golden_retriever</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>01e787576c003930f96c966f9c3e1d44</td>\n",
              "      <td>scottish_deerhound</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>01f429667104c0c5a5f321700f15435c</td>\n",
              "      <td>malamute</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>0206c12e8984e3c8a166cc272de25d6f</td>\n",
              "      <td>chihuahua</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>023e4e28415506e0deddcbd8f8bdab29</td>\n",
              "      <td>pug</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>02508e76981e1ba059d785704b4c480c</td>\n",
              "      <td>pug</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  id               breed\n",
              "4   0021f9ceb3235effd7fcde7f7538ed62    golden_retriever\n",
              "9   0042188c895a2f14ef64a918ed9c7b64  scottish_deerhound\n",
              "20  008b1271ed1addaccf93783b39deab45            doberman\n",
              "25  00a366d4b4a9bbb6c8a63126697b7656    golden_retriever\n",
              "37  0100f55e4f0fe28f2c0465d3fc4b9897    golden_retriever\n",
              "79  01e787576c003930f96c966f9c3e1d44  scottish_deerhound\n",
              "82  01f429667104c0c5a5f321700f15435c            malamute\n",
              "84  0206c12e8984e3c8a166cc272de25d6f           chihuahua\n",
              "92  023e4e28415506e0deddcbd8f8bdab29                 pug\n",
              "97  02508e76981e1ba059d785704b4c480c                 pug"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gGP17P7RlNq",
        "outputId": "8f0b2c40-4f45-4ef6-d86c-c9727849622f"
      },
      "source": [
        "# added .jpg at the end of each object in id column\r\n",
        "df1.id = df1.id + '.jpg'"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py:5170: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[name] = value\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onXXpJFlIWkj",
        "outputId": "eeda6f7d-800e-4f40-dcc2-63a8bd56187d"
      },
      "source": [
        "df1['breed'].value_counts()"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "scottish_deerhound    126\n",
              "beagle                105\n",
              "pug                    94\n",
              "saint_bernard          84\n",
              "malamute               81\n",
              "doberman               74\n",
              "chihuahua              71\n",
              "french_bulldog         70\n",
              "tibetan_mastiff        69\n",
              "golden_retriever       67\n",
              "Name: breed, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "yjA9agXJbIXi",
        "outputId": "808c10d4-0a4e-449f-bb8f-1b30a81f87dd"
      },
      "source": [
        "# breed_number = {'beagle':0, 'chihuahua':1, 'doberman':2,'french_bulldog':3, 'golden_retriever':4,\r\n",
        "#                    'malamute':5, 'pug':6, 'saint_bernard':7, 'scottish_deerhound':8,'tibetan_mastiff':9}\r\n",
        "# for i in breed_number:\r\n",
        "#   df1['breed'].replace(i, breed_number[i], inplace = True)\r\n",
        "# df1"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4582: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  method=method,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>breed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0021f9ceb3235effd7fcde7f7538ed62.jpg</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0042188c895a2f14ef64a918ed9c7b64.jpg</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>008b1271ed1addaccf93783b39deab45.jpg</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>00a366d4b4a9bbb6c8a63126697b7656.jpg</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0100f55e4f0fe28f2c0465d3fc4b9897.jpg</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10158</th>\n",
              "      <td>fe50bac6c389d137ea01c9cfc7346ca8.jpg</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10161</th>\n",
              "      <td>fe624532170510bd80627c0500bafc97.jpg</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10170</th>\n",
              "      <td>feb16cf86c9dac6d476e3c372ba5c279.jpg</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10172</th>\n",
              "      <td>febcab8eb2da444bf83336cffec7eb92.jpg</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10198</th>\n",
              "      <td>ff6f47aa8e181b6efa4d0be7b09b5628.jpg</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>841 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         id  breed\n",
              "4      0021f9ceb3235effd7fcde7f7538ed62.jpg      4\n",
              "9      0042188c895a2f14ef64a918ed9c7b64.jpg      8\n",
              "20     008b1271ed1addaccf93783b39deab45.jpg      2\n",
              "25     00a366d4b4a9bbb6c8a63126697b7656.jpg      4\n",
              "37     0100f55e4f0fe28f2c0465d3fc4b9897.jpg      4\n",
              "...                                     ...    ...\n",
              "10158  fe50bac6c389d137ea01c9cfc7346ca8.jpg      8\n",
              "10161  fe624532170510bd80627c0500bafc97.jpg      9\n",
              "10170  feb16cf86c9dac6d476e3c372ba5c279.jpg      6\n",
              "10172  febcab8eb2da444bf83336cffec7eb92.jpg      4\n",
              "10198  ff6f47aa8e181b6efa4d0be7b09b5628.jpg      4\n",
              "\n",
              "[841 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQ-4k1bPEy8w",
        "outputId": "71bc358d-6d5c-4c0a-900c-dda01004cf72"
      },
      "source": [
        "datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255, validation_split=0.1)\r\n",
        "\r\n",
        "train_generator = datagen.flow_from_dataframe(\r\n",
        "    df1,\r\n",
        "    directory=\"train/\",\r\n",
        "    x_col=\"id\",\r\n",
        "    y_col=\"breed\",\r\n",
        "    target_size=(224, 224),\r\n",
        "    batch_size=32, \r\n",
        "    subset=\"training\")\r\n",
        "\r\n",
        "validation_generator = datagen.flow_from_dataframe(\r\n",
        "    df1,\r\n",
        "    directory=\"train/\",\r\n",
        "    x_col=\"id\",\r\n",
        "    y_col=\"breed\",\r\n",
        "    target_size=(224, 224),\r\n",
        "    batch_size=32,\r\n",
        "    subset=\"validation\")"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 757 validated image filenames belonging to 10 classes.\n",
            "Found 84 validated image filenames belonging to 10 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDUnPJTMUDbm",
        "outputId": "1c0aa5ef-8ca8-4ec1-f9cd-59ed17f14e64"
      },
      "source": [
        "feature_extractor = keras.applications.ResNet50(input_shape=(224,224,3), include_top=False, weights='imagenet')\r\n",
        "feature_extractor.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 0s 0us/step\n",
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 23,534,592\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-KVsw6pYlnK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0772790c-1625-497c-9588-00c3a142060b"
      },
      "source": [
        "keras.backend.clear_session()\r\n",
        "\r\n",
        "model= keras.Sequential([\r\n",
        "                         feature_extractor,\r\n",
        "                         keras.layers.GlobalAveragePooling2D(),\r\n",
        "                         keras.layers.Flatten(),\r\n",
        "                         keras.layers.Dense(128, activation=\"relu\"),\r\n",
        "                         keras.layers.Dropout(0.4),\r\n",
        "                         keras.layers.Dense(64, activation=\"relu\"),\r\n",
        "                         keras.layers.Dropout(0.4),\r\n",
        "                         keras.layers.Dense(1, activation= \"relu\")\r\n",
        "])\r\n",
        "model.summary()"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50 (Functional)        (None, 7, 7, 2048)        23587712  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 23,858,305\n",
            "Trainable params: 23,805,185\n",
            "Non-trainable params: 53,120\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HudNnU9JaLX0"
      },
      "source": [
        "num_layers= 6\r\n",
        "feature_extractor.trainable= True;\r\n",
        "for Layers in model.layers[-num_layers:]:\r\n",
        "  Layers.trainable= True"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JolhxmbXap6Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fbef59e-74f8-490c-ccff-a7523fcf71b1"
      },
      "source": [
        "STEP_SIZE_TRAIN = int(np.ceil(train_generator.n / train_generator.batch_size))\r\n",
        "STEP_SIZE_VAL = int(np.ceil(validation_generator.n / validation_generator.batch_size))\r\n",
        "\r\n",
        "print(\"Train step size:\", STEP_SIZE_TRAIN)\r\n",
        "print(\"Validation step size:\", STEP_SIZE_VAL)\r\n",
        "\r\n",
        "train_generator.reset()\r\n",
        "validation_generator.reset()"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train step size: 24\n",
            "Validation step size: 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFk2O7xEaWpw"
      },
      "source": [
        "model.compile(\r\n",
        "    optimizer= keras.optimizers.Adam(learning_rate=0.01, name='Adam'),\r\n",
        "    loss= keras.losses.CategoricalCrossentropy(),\r\n",
        "    metrics=['accuracy']\r\n",
        ")"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7nxU6ck7p2b"
      },
      "source": [
        "# a check point callback to save our best weights\r\n",
        "checkpoint = keras.callbacks.ModelCheckpoint('dog_breed_classifier_model.h5', \r\n",
        "                                             monitor='val_accuracy', \r\n",
        "                                             verbose=1, save_best_only=True, \r\n",
        "                                             mode='max', save_weights_only=True)\r\n",
        "\r\n",
        "# a reducing lr callback to reduce lr when val_accuracy doesn't increase\r\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.2,\r\n",
        "                                              patience=2, verbose=1, mode='max',\r\n",
        "                                              min_delta=0.001, cooldown=2, min_lr=1e-7)\r\n"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSjxEGm6aWm2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95e4a4a7-30f2-4772-a5df-6e8d236f094a"
      },
      "source": [
        "history = model.fit_generator(train_generator,\r\n",
        "                              steps_per_epoch=STEP_SIZE_TRAIN,\r\n",
        "                              validation_data=validation_generator,\r\n",
        "                              validation_steps=STEP_SIZE_VAL,\r\n",
        "                              epochs=50, callbacks=[checkpoint, reduce_lr])"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            " 6/24 [======>.......................] - ETA: 5s - loss: nan - accuracy: 0.7733WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1178s vs `on_train_batch_end` time: 0.1862s). Check your callbacks.\n",
            "24/24 [==============================] - 14s 372ms/step - loss: nan - accuracy: 0.7737 - val_loss: nan - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.90000, saving model to dog_breed_classifier_model.h5\n",
            "Epoch 2/50\n",
            "24/24 [==============================] - 8s 333ms/step - loss: nan - accuracy: 0.7962 - val_loss: nan - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.90000\n",
            "Epoch 3/50\n",
            "24/24 [==============================] - 8s 333ms/step - loss: nan - accuracy: 0.7900 - val_loss: nan - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.1.\n",
            "Epoch 4/50\n",
            "24/24 [==============================] - 8s 337ms/step - loss: nan - accuracy: 0.7784 - val_loss: nan - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.90000\n",
            "Epoch 5/50\n",
            "24/24 [==============================] - 8s 338ms/step - loss: nan - accuracy: 0.7972 - val_loss: nan - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.90000\n",
            "Epoch 6/50\n",
            "24/24 [==============================] - 8s 335ms/step - loss: nan - accuracy: 0.7820 - val_loss: nan - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.020000000298023225.\n",
            "Epoch 7/50\n",
            "24/24 [==============================] - 8s 334ms/step - loss: nan - accuracy: 0.7768 - val_loss: nan - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.90000\n",
            "Epoch 8/50\n",
            "24/24 [==============================] - 8s 333ms/step - loss: nan - accuracy: 0.7954 - val_loss: nan - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.90000\n",
            "Epoch 9/50\n",
            "24/24 [==============================] - 8s 333ms/step - loss: nan - accuracy: 0.7894 - val_loss: nan - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.003999999910593033.\n",
            "Epoch 10/50\n",
            "24/24 [==============================] - 8s 332ms/step - loss: nan - accuracy: 0.7971 - val_loss: nan - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.90000\n",
            "Epoch 11/50\n",
            "24/24 [==============================] - 8s 332ms/step - loss: nan - accuracy: 0.8024 - val_loss: nan - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.90000\n",
            "Epoch 12/50\n",
            "24/24 [==============================] - 8s 332ms/step - loss: nan - accuracy: 0.7832 - val_loss: nan - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0007999999448657036.\n",
            "Epoch 13/50\n",
            "24/24 [==============================] - 8s 332ms/step - loss: nan - accuracy: 0.8005 - val_loss: nan - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.90000\n",
            "Epoch 14/50\n",
            "24/24 [==============================] - 8s 333ms/step - loss: nan - accuracy: 0.7846 - val_loss: nan - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.90000\n",
            "Epoch 15/50\n",
            "24/24 [==============================] - 8s 334ms/step - loss: nan - accuracy: 0.7929 - val_loss: nan - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00015999998431652786.\n",
            "Epoch 16/50\n",
            "24/24 [==============================] - 8s 337ms/step - loss: nan - accuracy: 0.7744 - val_loss: nan - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.90000\n",
            "Epoch 17/50\n",
            "24/24 [==============================] - 8s 333ms/step - loss: nan - accuracy: 0.7867 - val_loss: nan - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.90000\n",
            "Epoch 18/50\n",
            "24/24 [==============================] - 8s 336ms/step - loss: nan - accuracy: 0.7742 - val_loss: nan - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00018: ReduceLROnPlateau reducing learning rate to 3.199999628122896e-05.\n",
            "Epoch 19/50\n",
            "24/24 [==============================] - 8s 334ms/step - loss: nan - accuracy: 0.8286 - val_loss: nan - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.90000\n",
            "Epoch 20/50\n",
            "24/24 [==============================] - 8s 333ms/step - loss: nan - accuracy: 0.7881 - val_loss: nan - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.90000\n",
            "Epoch 21/50\n",
            "24/24 [==============================] - 8s 333ms/step - loss: nan - accuracy: 0.7878 - val_loss: nan - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "Epoch 22/50\n",
            "24/24 [==============================] - 8s 333ms/step - loss: nan - accuracy: 0.7602 - val_loss: nan - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.90000\n",
            "Epoch 23/50\n",
            "24/24 [==============================] - 8s 335ms/step - loss: nan - accuracy: 0.7839 - val_loss: nan - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.90000\n",
            "Epoch 24/50\n",
            "24/24 [==============================] - 8s 332ms/step - loss: nan - accuracy: 0.8080 - val_loss: nan - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.90000\n",
            "Epoch 25/50\n",
            "24/24 [==============================] - 8s 333ms/step - loss: nan - accuracy: 0.7692 - val_loss: nan - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.90000\n",
            "Epoch 26/50\n",
            "24/24 [==============================] - 8s 333ms/step - loss: nan - accuracy: 0.7876 - val_loss: nan - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.90000\n",
            "Epoch 27/50\n",
            "24/24 [==============================] - 8s 335ms/step - loss: nan - accuracy: 0.7873 - val_loss: nan - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.90000\n",
            "Epoch 28/50\n",
            "24/24 [==============================] - 8s 333ms/step - loss: nan - accuracy: 0.7898 - val_loss: nan - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.90000\n",
            "Epoch 29/50\n",
            "24/24 [==============================] - 8s 336ms/step - loss: nan - accuracy: 0.7907 - val_loss: nan - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.90000\n",
            "Epoch 30/50\n",
            "24/24 [==============================] - 8s 334ms/step - loss: nan - accuracy: 0.8235 - val_loss: nan - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.90000\n",
            "Epoch 31/50\n",
            "24/24 [==============================] - 8s 334ms/step - loss: nan - accuracy: 0.7769 - val_loss: nan - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.90000\n",
            "Epoch 32/50\n",
            "24/24 [==============================] - 8s 335ms/step - loss: nan - accuracy: 0.7947 - val_loss: nan - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.90000\n",
            "Epoch 33/50\n",
            "24/24 [==============================] - 8s 335ms/step - loss: nan - accuracy: 0.7885 - val_loss: nan - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.90000\n",
            "Epoch 34/50\n",
            "24/24 [==============================] - 8s 334ms/step - loss: nan - accuracy: 0.7706 - val_loss: nan - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.90000\n",
            "Epoch 35/50\n",
            "24/24 [==============================] - 8s 334ms/step - loss: nan - accuracy: 0.7923 - val_loss: nan - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.90000\n",
            "Epoch 36/50\n",
            "24/24 [==============================] - 8s 337ms/step - loss: nan - accuracy: 0.7796 - val_loss: nan - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.90000\n",
            "Epoch 37/50\n",
            "24/24 [==============================] - 8s 334ms/step - loss: nan - accuracy: 0.7889 - val_loss: nan - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.90000\n",
            "Epoch 38/50\n",
            "24/24 [==============================] - 8s 337ms/step - loss: nan - accuracy: 0.7737 - val_loss: nan - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.90000\n",
            "Epoch 39/50\n",
            "24/24 [==============================] - 8s 334ms/step - loss: nan - accuracy: 0.7925 - val_loss: nan - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.90000\n",
            "Epoch 40/50\n",
            "24/24 [==============================] - 8s 337ms/step - loss: nan - accuracy: 0.7738 - val_loss: nan - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.90000\n",
            "Epoch 41/50\n",
            "24/24 [==============================] - 8s 335ms/step - loss: nan - accuracy: 0.8019 - val_loss: nan - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.90000\n",
            "Epoch 42/50\n",
            "24/24 [==============================] - 8s 333ms/step - loss: nan - accuracy: 0.7811 - val_loss: nan - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.90000\n",
            "Epoch 43/50\n",
            "24/24 [==============================] - 8s 335ms/step - loss: nan - accuracy: 0.7969 - val_loss: nan - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.90000\n",
            "Epoch 44/50\n",
            "24/24 [==============================] - 8s 334ms/step - loss: nan - accuracy: 0.7898 - val_loss: nan - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.90000\n",
            "Epoch 45/50\n",
            "24/24 [==============================] - 8s 334ms/step - loss: nan - accuracy: 0.7933 - val_loss: nan - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.90000\n",
            "Epoch 46/50\n",
            "24/24 [==============================] - 8s 335ms/step - loss: nan - accuracy: 0.7955 - val_loss: nan - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.90000\n",
            "Epoch 47/50\n",
            "24/24 [==============================] - 8s 334ms/step - loss: nan - accuracy: 0.7850 - val_loss: nan - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.90000\n",
            "Epoch 48/50\n",
            "24/24 [==============================] - 8s 333ms/step - loss: nan - accuracy: 0.7741 - val_loss: nan - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.90000\n",
            "Epoch 49/50\n",
            "24/24 [==============================] - 8s 332ms/step - loss: nan - accuracy: 0.8030 - val_loss: nan - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.90000\n",
            "Epoch 50/50\n",
            "24/24 [==============================] - 8s 335ms/step - loss: nan - accuracy: 0.7803 - val_loss: nan - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.90000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4i3kZ3vaWkV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "c86b2afe-29b6-490c-dec4-ae8961e6845a"
      },
      "source": [
        "plt.plot(history.history['accuracy'])\r\n",
        "plt.plot(history.history['val_accuracy'])\r\n",
        "plt.title('Model Accuracy')\r\n",
        "plt.ylabel('Accuracy')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.legend(['Train', 'Validation'], loc='best')\r\n",
        "plt.show()"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vsmo_KLd1WNR"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwFCgI6Y1V7k"
      },
      "source": [
        "uploaded= files.upload()\r\n",
        "\r\n",
        "for fn in uploaded.keys():\r\n",
        "  # predict image\r\n",
        "  path='/content/' + fn\r\n",
        "  img= image.load_img(path, target_size=(300,300))\r\n",
        "  plt.axis('off')\r\n",
        "  plt.imshow(img)\r\n",
        "  plt.show()\r\n",
        "  x= image.img_to_array(img)\r\n",
        "  x= np.expand_dims(x, axis=0)\r\n",
        "  \r\n",
        "  images= np.vstack([x])\r\n",
        "  classes= model.predict(images, batch_size=10)\r\n",
        "  print(classes[0])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}